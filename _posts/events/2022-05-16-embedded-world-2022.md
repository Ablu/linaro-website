---
title: Embedded World 2022
event: Embedded-World-2022
event_url: https://www.embedded-world.de/en
description: "Linaro will present two sessions at the Embedded World 2022
  Conference  - one on Embedded AI and another on Virtualization in Automotive.
  "
location: Nuremburg
date: 2022-05-16 08:35:59 +01:00
event_date: 2022-06-21 08:46:21 +01:00
event_end_date: 2022-06-23 08:35:59 +01:00
image: /assets/images/content/ew22.jpg
event_type: presenter
---
[Embedded World](https://www.embedded-world.de/en) is one of the leading trade fairs for embedded system technologies. At the upcoming conference, Linaro will present two sessions:

# Embedded Hypervisor: Ready for Prime Time?

**Wednesday 22 June, 16.00 GMT +2**

Francois Ozog from Linaro’s Edge Computing Group will talk about virtualization in embedded marketswith a focus on automotive (you can find the session [here under “Automotive OS 2”](https://www.embedded-world.de/en/conferences-programme/programme-overview)). Ensuring deterministic workloads can operate as designed and migrating them to a backup zone in the context of a Software Defined Vehicle (SDV) can be quite a challenge for embedded product designers. This session aims to help architects get clarity on virtualization by focusing on four areas: realtime, functional safety, new recipes, and confidential computing. 

# Securing Embedded AI with Open Source Firmware

**Thursday 23 June, 13.45 GMT +2**

Bill Fletcher and Kevin Townsend from Linaro’s IoT and Embedded Group will present Linaro’s Confidential AI Project in the conference session “Securing Embedded AI with Open Source Firmware ([Session 4.9](https://www.embedded-world.de/en/conferences-programme/programme-overview?lectureId=vvPLPdUW74Wmw0xWe8f3))”. Linaro’s IoT and Embedded Group works predominantly on microcontrollers both on the latest hardware from our member companies and in advance of hardware on virtual platforms. This talk covers all aspects which can be protected by firmware mechanisms; the specifics of secure enclave execution of ML inference to protect both models and data; secure model storage, and configuration and update mechanisms.